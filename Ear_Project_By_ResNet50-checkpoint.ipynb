{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dbfb23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANAY\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANAY\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - accuracy: 0.0064 - loss: 5.0102\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3s/step - accuracy: 0.0019 - loss: 4.8544\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.0263 - loss: 4.8088\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.0351 - loss: 4.7619\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.0440 - loss: 4.7513\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.0519 - loss: 4.7376\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - accuracy: 0.0507 - loss: 4.7255\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.0584 - loss: 4.7164\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.0772 - loss: 4.7103\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.0789 - loss: 4.6770\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For data augmentation (optional)\n",
    "from sklearn.preprocessing import OneHotEncoder  # For label encoding\n",
    "\n",
    "# Path to your raw images folder\n",
    "data_dir = \"C:/Users/PRANAY/OneDrive/Desktop/Ear Recoginition System_Mini Project_6sem/ear/raw\"\n",
    "\n",
    "# Define number of classes (number of subjects in your dataset)\n",
    "num_classes = 125\n",
    "\n",
    "# Load and preprocess raw images\n",
    "X = []\n",
    "y = []  # List to store labels (modify as needed)\n",
    "for filename in os.listdir(data_dir):\n",
    "  if not filename.endswith('.bmp'):\n",
    "    continue  # Skip non-BMP files\n",
    "  img_path = os.path.join(data_dir, filename)\n",
    "  # Extract label from filename or separate label directory (modify as needed)\n",
    "  # This example assumes the label is the first part of the filename before the underscore\n",
    "  label = filename.split(\"_\")[0]\n",
    "  y.append(label)  # Append label\n",
    "\n",
    "  try:\n",
    "    img = Image.open(img_path)\n",
    "    img = img.convert('RGB')  # Convert to RGB if grayscale\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img)\n",
    "    # Normalize (optional)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    if img_array is not None:\n",
    "      X.append(img_array)\n",
    "  except Exception as e:\n",
    "    print(f\"Error processing image {img_path}: {e}\")\n",
    "\n",
    "if len(X) == 0:\n",
    "  print(\"No valid images found in the dataset. Please check the dataset.\")\n",
    "else:\n",
    "  X = np.array(X, dtype=np.float32)  # Ensure data type\n",
    "\n",
    "  # One-hot encode labels\n",
    "  encoder = OneHotEncoder(sparse=False)\n",
    "  y = encoder.fit_transform(np.array([[l] for l in y]))  # Reshape for encoder\n",
    "\n",
    "  # Data augmentation (optional)\n",
    "  datagen = ImageDataGenerator(\n",
    "      rotation_range=20,  # Randomly rotate images\n",
    "      width_shift_range=0.2,  # Randomly shift images horizontally\n",
    "      height_shift_range=0.2,  # Randomly shift images vertically\n",
    "      shear_range=0.2,  # Randomly shear images\n",
    "      zoom_range=0.2,  # Randomly zoom images\n",
    "      horizontal_flip=True  # Randomly flip images horizontally\n",
    "  )\n",
    "  datagen.fit(X)  # Fit data augmentation on training data\n",
    "\n",
    "  # Load pre-trained VGG16 model\n",
    "  base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "  # Freeze pre-trained layers (optional, you can experiment with unfreezing some)\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  # Add custom layers\n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  # Create final model\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  # Train the model\n",
    "  model.fit(datagen.flow(X, y, batch_size=32), epochs=10)  # Use data augmentation\n",
    "\n",
    "  # Save the model (optional)\n",
    "  #model.save('ear_recognition_model.h5')\n",
    "\n",
    "  # ... (use the trained model for prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6784d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a44cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde005b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59d1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "618caf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping non-directory entry: 001_1.bmp\n",
      "Skipping non-directory entry: 001_2.bmp\n",
      "Skipping non-directory entry: 001_3.bmp\n",
      "Skipping non-directory entry: 001_4.bmp\n",
      "Skipping non-directory entry: 001_5.bmp\n",
      "Skipping non-directory entry: 001_6.bmp\n",
      "Skipping non-directory entry: 002_1.bmp\n",
      "Skipping non-directory entry: 002_2.bmp\n",
      "Skipping non-directory entry: 002_3.bmp\n",
      "Skipping non-directory entry: 003_1.bmp\n",
      "Skipping non-directory entry: 003_2.bmp\n",
      "Skipping non-directory entry: 003_3.bmp\n",
      "Skipping non-directory entry: 003_4.bmp\n",
      "Skipping non-directory entry: 003_5.bmp\n",
      "Skipping non-directory entry: 004_1.bmp\n",
      "Skipping non-directory entry: 004_2.bmp\n",
      "Skipping non-directory entry: 004_3.bmp\n",
      "Skipping non-directory entry: 004_4.bmp\n",
      "Skipping non-directory entry: 004_5.bmp\n",
      "Skipping non-directory entry: 004_6.bmp\n",
      "Skipping non-directory entry: 005_1.bmp\n",
      "Skipping non-directory entry: 005_2.bmp\n",
      "Skipping non-directory entry: 005_3.bmp\n",
      "Skipping non-directory entry: 005_4.bmp\n",
      "Skipping non-directory entry: 006_1.bmp\n",
      "Skipping non-directory entry: 006_2.bmp\n",
      "Skipping non-directory entry: 006_3.bmp\n",
      "Skipping non-directory entry: 007_1.bmp\n",
      "Skipping non-directory entry: 007_2.bmp\n",
      "Skipping non-directory entry: 007_3.bmp\n",
      "Skipping non-directory entry: 007_4.bmp\n",
      "Skipping non-directory entry: 008_1.bmp\n",
      "Skipping non-directory entry: 008_2.bmp\n",
      "Skipping non-directory entry: 008_3.bmp\n",
      "Skipping non-directory entry: 009_1.bmp\n",
      "Skipping non-directory entry: 009_2.bmp\n",
      "Skipping non-directory entry: 009_3.bmp\n",
      "Skipping non-directory entry: 010_1.bmp\n",
      "Skipping non-directory entry: 010_2.bmp\n",
      "Skipping non-directory entry: 010_3.bmp\n",
      "Skipping non-directory entry: 011_1.bmp\n",
      "Skipping non-directory entry: 011_2.bmp\n",
      "Skipping non-directory entry: 011_3.bmp\n",
      "Skipping non-directory entry: 012_1.bmp\n",
      "Skipping non-directory entry: 012_2.bmp\n",
      "Skipping non-directory entry: 012_3.bmp\n",
      "Skipping non-directory entry: 013_1.bmp\n",
      "Skipping non-directory entry: 013_2.bmp\n",
      "Skipping non-directory entry: 013_3.bmp\n",
      "Skipping non-directory entry: 013_4.bmp\n",
      "Skipping non-directory entry: 013_5.bmp\n",
      "Skipping non-directory entry: 013_6.bmp\n",
      "Skipping non-directory entry: 014_1.bmp\n",
      "Skipping non-directory entry: 014_2.bmp\n",
      "Skipping non-directory entry: 014_3.bmp\n",
      "Skipping non-directory entry: 015_1.bmp\n",
      "Skipping non-directory entry: 015_2.bmp\n",
      "Skipping non-directory entry: 015_3.bmp\n",
      "Skipping non-directory entry: 016_1.bmp\n",
      "Skipping non-directory entry: 016_2.bmp\n",
      "Skipping non-directory entry: 016_3.bmp\n",
      "Skipping non-directory entry: 016_4.bmp\n",
      "Skipping non-directory entry: 017_1.bmp\n",
      "Skipping non-directory entry: 017_2.bmp\n",
      "Skipping non-directory entry: 017_3.bmp\n",
      "Skipping non-directory entry: 018_1.bmp\n",
      "Skipping non-directory entry: 018_2.bmp\n",
      "Skipping non-directory entry: 018_3.bmp\n",
      "Skipping non-directory entry: 019_1.bmp\n",
      "Skipping non-directory entry: 019_2.bmp\n",
      "Skipping non-directory entry: 019_3.bmp\n",
      "Skipping non-directory entry: 019_4.bmp\n",
      "Skipping non-directory entry: 020_1.bmp\n",
      "Skipping non-directory entry: 020_2.bmp\n",
      "Skipping non-directory entry: 020_3.bmp\n",
      "Skipping non-directory entry: 021_1.bmp\n",
      "Skipping non-directory entry: 021_2.bmp\n",
      "Skipping non-directory entry: 021_3.bmp\n",
      "Skipping non-directory entry: 022_1.bmp\n",
      "Skipping non-directory entry: 022_2.bmp\n",
      "Skipping non-directory entry: 022_3.bmp\n",
      "Skipping non-directory entry: 023_1.bmp\n",
      "Skipping non-directory entry: 023_2.bmp\n",
      "Skipping non-directory entry: 023_3.bmp\n",
      "Skipping non-directory entry: 023_4.bmp\n",
      "Skipping non-directory entry: 024_1.bmp\n",
      "Skipping non-directory entry: 024_2.bmp\n",
      "Skipping non-directory entry: 024_3.bmp\n",
      "Skipping non-directory entry: 024_4.bmp\n",
      "Skipping non-directory entry: 025_1.bmp\n",
      "Skipping non-directory entry: 025_2.bmp\n",
      "Skipping non-directory entry: 025_3.bmp\n",
      "Skipping non-directory entry: 025_4.bmp\n",
      "Skipping non-directory entry: 026_1.bmp\n",
      "Skipping non-directory entry: 026_2.bmp\n",
      "Skipping non-directory entry: 026_3.bmp\n",
      "Skipping non-directory entry: 027_1.bmp\n",
      "Skipping non-directory entry: 027_2.bmp\n",
      "Skipping non-directory entry: 027_3.bmp\n",
      "Skipping non-directory entry: 027_4.bmp\n",
      "Skipping non-directory entry: 027_5.bmp\n",
      "Skipping non-directory entry: 028_1.bmp\n",
      "Skipping non-directory entry: 028_2.bmp\n",
      "Skipping non-directory entry: 028_3.bmp\n",
      "Skipping non-directory entry: 029_1.bmp\n",
      "Skipping non-directory entry: 029_2.bmp\n",
      "Skipping non-directory entry: 029_3.bmp\n",
      "Skipping non-directory entry: 029_4.bmp\n",
      "Skipping non-directory entry: 030_1.bmp\n",
      "Skipping non-directory entry: 030_2.bmp\n",
      "Skipping non-directory entry: 030_3.bmp\n",
      "Skipping non-directory entry: 030_4.bmp\n",
      "Skipping non-directory entry: 031_1.bmp\n",
      "Skipping non-directory entry: 031_2.bmp\n",
      "Skipping non-directory entry: 031_3.bmp\n",
      "Skipping non-directory entry: 032_1.bmp\n",
      "Skipping non-directory entry: 032_2.bmp\n",
      "Skipping non-directory entry: 032_3.bmp\n",
      "Skipping non-directory entry: 032_4.bmp\n",
      "Skipping non-directory entry: 033_1.bmp\n",
      "Skipping non-directory entry: 033_2.bmp\n",
      "Skipping non-directory entry: 033_3.bmp\n",
      "Skipping non-directory entry: 034_1.bmp\n",
      "Skipping non-directory entry: 034_2.bmp\n",
      "Skipping non-directory entry: 034_3.bmp\n",
      "Skipping non-directory entry: 035_1.bmp\n",
      "Skipping non-directory entry: 035_2.bmp\n",
      "Skipping non-directory entry: 035_3.bmp\n",
      "Skipping non-directory entry: 035_4.bmp\n",
      "Skipping non-directory entry: 036_1.bmp\n",
      "Skipping non-directory entry: 036_2.bmp\n",
      "Skipping non-directory entry: 036_3.bmp\n",
      "Skipping non-directory entry: 037_1.bmp\n",
      "Skipping non-directory entry: 037_2.bmp\n",
      "Skipping non-directory entry: 037_3.bmp\n",
      "Skipping non-directory entry: 037_4.bmp\n",
      "Skipping non-directory entry: 038_1.bmp\n",
      "Skipping non-directory entry: 038_2.bmp\n",
      "Skipping non-directory entry: 038_3.bmp\n",
      "Skipping non-directory entry: 039_1.bmp\n",
      "Skipping non-directory entry: 039_2.bmp\n",
      "Skipping non-directory entry: 039_3.bmp\n",
      "Skipping non-directory entry: 040_1.bmp\n",
      "Skipping non-directory entry: 040_2.bmp\n",
      "Skipping non-directory entry: 040_3.bmp\n",
      "Skipping non-directory entry: 041_1.bmp\n",
      "Skipping non-directory entry: 041_2.bmp\n",
      "Skipping non-directory entry: 041_3.bmp\n",
      "Skipping non-directory entry: 041_4.bmp\n",
      "Skipping non-directory entry: 042_1.bmp\n",
      "Skipping non-directory entry: 042_2.bmp\n",
      "Skipping non-directory entry: 042_3.bmp\n",
      "Skipping non-directory entry: 042_4.bmp\n",
      "Skipping non-directory entry: 043_1.bmp\n",
      "Skipping non-directory entry: 043_2.bmp\n",
      "Skipping non-directory entry: 043_3.bmp\n",
      "Skipping non-directory entry: 043_4.bmp\n",
      "Skipping non-directory entry: 043_5.bmp\n",
      "Skipping non-directory entry: 044_1.bmp\n",
      "Skipping non-directory entry: 044_2.bmp\n",
      "Skipping non-directory entry: 044_3.bmp\n",
      "Skipping non-directory entry: 045_1.bmp\n",
      "Skipping non-directory entry: 045_2.bmp\n",
      "Skipping non-directory entry: 045_3.bmp\n",
      "Skipping non-directory entry: 046_1.bmp\n",
      "Skipping non-directory entry: 046_2.bmp\n",
      "Skipping non-directory entry: 046_3.bmp\n",
      "Skipping non-directory entry: 046_4.bmp\n",
      "Skipping non-directory entry: 047_1.bmp\n",
      "Skipping non-directory entry: 047_2.bmp\n",
      "Skipping non-directory entry: 047_3.bmp\n",
      "Skipping non-directory entry: 048_1.bmp\n",
      "Skipping non-directory entry: 048_2.bmp\n",
      "Skipping non-directory entry: 048_3.bmp\n",
      "Skipping non-directory entry: 049_1.bmp\n",
      "Skipping non-directory entry: 049_2.bmp\n",
      "Skipping non-directory entry: 049_3.bmp\n",
      "Skipping non-directory entry: 049_4.bmp\n",
      "Skipping non-directory entry: 049_5.bmp\n",
      "Skipping non-directory entry: 050_1.bmp\n",
      "Skipping non-directory entry: 050_2.bmp\n",
      "Skipping non-directory entry: 050_3.bmp\n",
      "Skipping non-directory entry: 050_4.bmp\n",
      "Skipping non-directory entry: 050_5.bmp\n",
      "Skipping non-directory entry: 051_1.bmp\n",
      "Skipping non-directory entry: 051_2.bmp\n",
      "Skipping non-directory entry: 051_3.bmp\n",
      "Skipping non-directory entry: 052_1.bmp\n",
      "Skipping non-directory entry: 052_2.bmp\n",
      "Skipping non-directory entry: 052_3.bmp\n",
      "Skipping non-directory entry: 052_4.bmp\n",
      "Skipping non-directory entry: 053_1.bmp\n",
      "Skipping non-directory entry: 053_2.bmp\n",
      "Skipping non-directory entry: 053_3.bmp\n",
      "Skipping non-directory entry: 054_1.bmp\n",
      "Skipping non-directory entry: 054_2.bmp\n",
      "Skipping non-directory entry: 054_3.bmp\n",
      "Skipping non-directory entry: 054_4.bmp\n",
      "Skipping non-directory entry: 054_5.bmp\n",
      "Skipping non-directory entry: 055_1.bmp\n",
      "Skipping non-directory entry: 055_2.bmp\n",
      "Skipping non-directory entry: 055_3.bmp\n",
      "Skipping non-directory entry: 055_4.bmp\n",
      "Skipping non-directory entry: 055_5.bmp\n",
      "Skipping non-directory entry: 056_1.bmp\n",
      "Skipping non-directory entry: 056_2.bmp\n",
      "Skipping non-directory entry: 056_3.bmp\n",
      "Skipping non-directory entry: 056_4.bmp\n",
      "Skipping non-directory entry: 057_1.bmp\n",
      "Skipping non-directory entry: 057_2.bmp\n",
      "Skipping non-directory entry: 057_3.bmp\n",
      "Skipping non-directory entry: 057_4.bmp\n",
      "Skipping non-directory entry: 058_1.bmp\n",
      "Skipping non-directory entry: 058_2.bmp\n",
      "Skipping non-directory entry: 058_3.bmp\n",
      "Skipping non-directory entry: 058_4.bmp\n",
      "Skipping non-directory entry: 058_5.bmp\n",
      "Skipping non-directory entry: 059_1.bmp\n",
      "Skipping non-directory entry: 059_2.bmp\n",
      "Skipping non-directory entry: 059_3.bmp\n",
      "Skipping non-directory entry: 059_4.bmp\n",
      "Skipping non-directory entry: 059_5.bmp\n",
      "Skipping non-directory entry: 060_1.bmp\n",
      "Skipping non-directory entry: 060_2.bmp\n",
      "Skipping non-directory entry: 060_3.bmp\n",
      "Skipping non-directory entry: 061_1.bmp\n",
      "Skipping non-directory entry: 061_2.bmp\n",
      "Skipping non-directory entry: 061_3.bmp\n",
      "Skipping non-directory entry: 062_1.bmp\n",
      "Skipping non-directory entry: 062_2.bmp\n",
      "Skipping non-directory entry: 062_3.bmp\n",
      "Skipping non-directory entry: 063_1.bmp\n",
      "Skipping non-directory entry: 063_2.bmp\n",
      "Skipping non-directory entry: 063_3.bmp\n",
      "Skipping non-directory entry: 063_4.bmp\n",
      "Skipping non-directory entry: 063_5.bmp\n",
      "Skipping non-directory entry: 063_6.bmp\n",
      "Skipping non-directory entry: 064_1.bmp\n",
      "Skipping non-directory entry: 064_2.bmp\n",
      "Skipping non-directory entry: 064_3.bmp\n",
      "Skipping non-directory entry: 064_4.bmp\n",
      "Skipping non-directory entry: 064_5.bmp\n",
      "Skipping non-directory entry: 064_6.bmp\n",
      "Skipping non-directory entry: 065_1.bmp\n",
      "Skipping non-directory entry: 065_2.bmp\n",
      "Skipping non-directory entry: 065_3.bmp\n",
      "Skipping non-directory entry: 066_1.bmp\n",
      "Skipping non-directory entry: 066_2.bmp\n",
      "Skipping non-directory entry: 066_3.bmp\n",
      "Skipping non-directory entry: 066_4.bmp\n",
      "Skipping non-directory entry: 067_1.bmp\n",
      "Skipping non-directory entry: 067_2.bmp\n",
      "Skipping non-directory entry: 067_3.bmp\n",
      "Skipping non-directory entry: 068_1.bmp\n",
      "Skipping non-directory entry: 068_2.bmp\n",
      "Skipping non-directory entry: 068_3.bmp\n",
      "Skipping non-directory entry: 068_4.bmp\n",
      "Skipping non-directory entry: 069_1.bmp\n",
      "Skipping non-directory entry: 069_2.bmp\n",
      "Skipping non-directory entry: 069_3.bmp\n",
      "Skipping non-directory entry: 069_4.bmp\n",
      "Skipping non-directory entry: 069_5.bmp\n",
      "Skipping non-directory entry: 070_1.bmp\n",
      "Skipping non-directory entry: 070_2.bmp\n",
      "Skipping non-directory entry: 070_3.bmp\n",
      "Skipping non-directory entry: 070_4.bmp\n",
      "Skipping non-directory entry: 071_1.bmp\n",
      "Skipping non-directory entry: 071_2.bmp\n",
      "Skipping non-directory entry: 071_3.bmp\n",
      "Skipping non-directory entry: 072_1.bmp\n",
      "Skipping non-directory entry: 072_2.bmp\n",
      "Skipping non-directory entry: 072_3.bmp\n",
      "Skipping non-directory entry: 073_1.bmp\n",
      "Skipping non-directory entry: 073_2.bmp\n",
      "Skipping non-directory entry: 073_3.bmp\n",
      "Skipping non-directory entry: 074_1.bmp\n",
      "Skipping non-directory entry: 074_2.bmp\n",
      "Skipping non-directory entry: 074_3.bmp\n",
      "Skipping non-directory entry: 075_1.bmp\n",
      "Skipping non-directory entry: 075_2.bmp\n",
      "Skipping non-directory entry: 075_3.bmp\n",
      "Skipping non-directory entry: 076_1.bmp\n",
      "Skipping non-directory entry: 076_2.bmp\n",
      "Skipping non-directory entry: 076_3.bmp\n",
      "Skipping non-directory entry: 076_4.bmp\n",
      "Skipping non-directory entry: 076_5.bmp\n",
      "Skipping non-directory entry: 076_6.bmp\n",
      "Skipping non-directory entry: 077_1.bmp\n",
      "Skipping non-directory entry: 077_2.bmp\n",
      "Skipping non-directory entry: 077_3.bmp\n",
      "Skipping non-directory entry: 078_1.bmp\n",
      "Skipping non-directory entry: 078_2.bmp\n",
      "Skipping non-directory entry: 078_3.bmp\n",
      "Skipping non-directory entry: 079_1.bmp\n",
      "Skipping non-directory entry: 079_2.bmp\n",
      "Skipping non-directory entry: 079_3.bmp\n",
      "Skipping non-directory entry: 080_1.bmp\n",
      "Skipping non-directory entry: 080_2.bmp\n",
      "Skipping non-directory entry: 080_3.bmp\n",
      "Skipping non-directory entry: 080_4.bmp\n",
      "Skipping non-directory entry: 080_5.bmp\n",
      "Skipping non-directory entry: 081_1.bmp\n",
      "Skipping non-directory entry: 081_2.bmp\n",
      "Skipping non-directory entry: 081_3.bmp\n",
      "Skipping non-directory entry: 081_4.bmp\n",
      "Skipping non-directory entry: 082_1.bmp\n",
      "Skipping non-directory entry: 082_2.bmp\n",
      "Skipping non-directory entry: 082_3.bmp\n",
      "Skipping non-directory entry: 082_4.bmp\n",
      "Skipping non-directory entry: 083_1.bmp\n",
      "Skipping non-directory entry: 083_2.bmp\n",
      "Skipping non-directory entry: 083_3.bmp\n",
      "Skipping non-directory entry: 083_4.bmp\n",
      "Skipping non-directory entry: 084_1.bmp\n",
      "Skipping non-directory entry: 084_2.bmp\n",
      "Skipping non-directory entry: 084_3.bmp\n",
      "Skipping non-directory entry: 085_1.bmp\n",
      "Skipping non-directory entry: 085_2.bmp\n",
      "Skipping non-directory entry: 085_3.bmp\n",
      "Skipping non-directory entry: 085_4.bmp\n",
      "Skipping non-directory entry: 085_5.bmp\n",
      "Skipping non-directory entry: 085_6.bmp\n",
      "Skipping non-directory entry: 086_1.bmp\n",
      "Skipping non-directory entry: 086_2.bmp\n",
      "Skipping non-directory entry: 086_3.bmp\n",
      "Skipping non-directory entry: 086_4.bmp\n",
      "Skipping non-directory entry: 086_5.bmp\n",
      "Skipping non-directory entry: 087_1.bmp\n",
      "Skipping non-directory entry: 087_2.bmp\n",
      "Skipping non-directory entry: 087_3.bmp\n",
      "Skipping non-directory entry: 087_4.bmp\n",
      "Skipping non-directory entry: 088_1.bmp\n",
      "Skipping non-directory entry: 088_2.bmp\n",
      "Skipping non-directory entry: 088_3.bmp\n",
      "Skipping non-directory entry: 088_4.bmp\n",
      "Skipping non-directory entry: 088_5.bmp\n",
      "Skipping non-directory entry: 089_1.bmp\n",
      "Skipping non-directory entry: 089_2.bmp\n",
      "Skipping non-directory entry: 089_3.bmp\n",
      "Skipping non-directory entry: 089_4.bmp\n",
      "Skipping non-directory entry: 090_1.bmp\n",
      "Skipping non-directory entry: 090_2.bmp\n",
      "Skipping non-directory entry: 090_3.bmp\n",
      "Skipping non-directory entry: 090_4.bmp\n",
      "Skipping non-directory entry: 091_1.bmp\n",
      "Skipping non-directory entry: 091_2.bmp\n",
      "Skipping non-directory entry: 091_3.bmp\n",
      "Skipping non-directory entry: 091_4.bmp\n",
      "Skipping non-directory entry: 091_5.bmp\n",
      "Skipping non-directory entry: 091_6.bmp\n",
      "Skipping non-directory entry: 092_1.bmp\n",
      "Skipping non-directory entry: 092_2.bmp\n",
      "Skipping non-directory entry: 092_3.bmp\n",
      "Skipping non-directory entry: 093_1.bmp\n",
      "Skipping non-directory entry: 093_2.bmp\n",
      "Skipping non-directory entry: 093_3.bmp\n",
      "Skipping non-directory entry: 093_4.bmp\n",
      "Skipping non-directory entry: 093_5.bmp\n",
      "Skipping non-directory entry: 093_6.bmp\n",
      "Skipping non-directory entry: 094_1.bmp\n",
      "Skipping non-directory entry: 094_2.bmp\n",
      "Skipping non-directory entry: 094_3.bmp\n",
      "Skipping non-directory entry: 094_4.bmp\n",
      "Skipping non-directory entry: 095_1.bmp\n",
      "Skipping non-directory entry: 095_2.bmp\n",
      "Skipping non-directory entry: 095_3.bmp\n",
      "Skipping non-directory entry: 095_4.bmp\n",
      "Skipping non-directory entry: 096_1.bmp\n",
      "Skipping non-directory entry: 096_2.bmp\n",
      "Skipping non-directory entry: 096_3.bmp\n",
      "Skipping non-directory entry: 096_4.bmp\n",
      "Skipping non-directory entry: 096_5.bmp\n",
      "Skipping non-directory entry: 096_6.bmp\n",
      "Skipping non-directory entry: 097_1.bmp\n",
      "Skipping non-directory entry: 097_2.bmp\n",
      "Skipping non-directory entry: 097_3.bmp\n",
      "Skipping non-directory entry: 098_1.bmp\n",
      "Skipping non-directory entry: 098_2.bmp\n",
      "Skipping non-directory entry: 098_3.bmp\n",
      "Skipping non-directory entry: 098_4.bmp\n",
      "Skipping non-directory entry: 099_1.bmp\n",
      "Skipping non-directory entry: 099_2.bmp\n",
      "Skipping non-directory entry: 099_3.bmp\n",
      "Skipping non-directory entry: 099_4.bmp\n",
      "Skipping non-directory entry: 099_5.bmp\n",
      "Skipping non-directory entry: 099_6.bmp\n",
      "Skipping non-directory entry: 100_1.bmp\n",
      "Skipping non-directory entry: 100_2.bmp\n",
      "Skipping non-directory entry: 100_3.bmp\n",
      "Skipping non-directory entry: 101_1.bmp\n",
      "Skipping non-directory entry: 101_2.bmp\n",
      "Skipping non-directory entry: 101_3.bmp\n",
      "Skipping non-directory entry: 101_4.bmp\n",
      "Skipping non-directory entry: 101_5.bmp\n",
      "Skipping non-directory entry: 101_6.bmp\n",
      "Skipping non-directory entry: 102_1.bmp\n",
      "Skipping non-directory entry: 102_2.bmp\n",
      "Skipping non-directory entry: 102_3.bmp\n",
      "Skipping non-directory entry: 102_4.bmp\n",
      "Skipping non-directory entry: 102_5.bmp\n",
      "Skipping non-directory entry: 103_1.bmp\n",
      "Skipping non-directory entry: 103_2.bmp\n",
      "Skipping non-directory entry: 103_3.bmp\n",
      "Skipping non-directory entry: 103_4.bmp\n",
      "Skipping non-directory entry: 104_1.bmp\n",
      "Skipping non-directory entry: 104_2.bmp\n",
      "Skipping non-directory entry: 104_3.bmp\n",
      "Skipping non-directory entry: 104_4.bmp\n",
      "Skipping non-directory entry: 105_1.bmp\n",
      "Skipping non-directory entry: 105_2.bmp\n",
      "Skipping non-directory entry: 105_3.bmp\n",
      "Skipping non-directory entry: 106_1.bmp\n",
      "Skipping non-directory entry: 106_2.bmp\n",
      "Skipping non-directory entry: 106_3.bmp\n",
      "Skipping non-directory entry: 107_1.bmp\n",
      "Skipping non-directory entry: 107_2.bmp\n",
      "Skipping non-directory entry: 107_3.bmp\n",
      "Skipping non-directory entry: 107_4.bmp\n",
      "Skipping non-directory entry: 108_1.bmp\n",
      "Skipping non-directory entry: 108_2.bmp\n",
      "Skipping non-directory entry: 108_3.bmp\n",
      "Skipping non-directory entry: 108_4.bmp\n",
      "Skipping non-directory entry: 109_1.bmp\n",
      "Skipping non-directory entry: 109_2.bmp\n",
      "Skipping non-directory entry: 109_3.bmp\n",
      "Skipping non-directory entry: 110_1.bmp\n",
      "Skipping non-directory entry: 110_2.bmp\n",
      "Skipping non-directory entry: 110_3.bmp\n",
      "Skipping non-directory entry: 111_1.bmp\n",
      "Skipping non-directory entry: 111_2.bmp\n",
      "Skipping non-directory entry: 111_3.bmp\n",
      "Skipping non-directory entry: 112_1.bmp\n",
      "Skipping non-directory entry: 112_2.bmp\n",
      "Skipping non-directory entry: 112_3.bmp\n",
      "Skipping non-directory entry: 112_4.bmp\n",
      "Skipping non-directory entry: 113_1.bmp\n",
      "Skipping non-directory entry: 113_2.bmp\n",
      "Skipping non-directory entry: 113_3.bmp\n",
      "Skipping non-directory entry: 114_1.bmp\n",
      "Skipping non-directory entry: 114_2.bmp\n",
      "Skipping non-directory entry: 114_3.bmp\n",
      "Skipping non-directory entry: 114_4.bmp\n",
      "Skipping non-directory entry: 114_5.bmp\n",
      "Skipping non-directory entry: 115_1.bmp\n",
      "Skipping non-directory entry: 115_2.bmp\n",
      "Skipping non-directory entry: 115_3.bmp\n",
      "Skipping non-directory entry: 115_4.bmp\n",
      "Skipping non-directory entry: 116_1.bmp\n",
      "Skipping non-directory entry: 116_2.bmp\n",
      "Skipping non-directory entry: 116_3.bmp\n",
      "Skipping non-directory entry: 116_4.bmp\n",
      "Skipping non-directory entry: 116_5.bmp\n",
      "Skipping non-directory entry: 117_1.bmp\n",
      "Skipping non-directory entry: 117_2.bmp\n",
      "Skipping non-directory entry: 117_3.bmp\n",
      "Skipping non-directory entry: 117_4.bmp\n",
      "Skipping non-directory entry: 118_1.bmp\n",
      "Skipping non-directory entry: 118_2.bmp\n",
      "Skipping non-directory entry: 118_3.bmp\n",
      "Skipping non-directory entry: 119_1.bmp\n",
      "Skipping non-directory entry: 119_2.bmp\n",
      "Skipping non-directory entry: 119_3.bmp\n",
      "Skipping non-directory entry: 119_4.bmp\n",
      "Skipping non-directory entry: 120_1.bmp\n",
      "Skipping non-directory entry: 120_2.bmp\n",
      "Skipping non-directory entry: 120_3.bmp\n",
      "Skipping non-directory entry: 120_4.bmp\n",
      "Skipping non-directory entry: 121_1.bmp\n",
      "Skipping non-directory entry: 121_2.bmp\n",
      "Skipping non-directory entry: 121_3.bmp\n",
      "Skipping non-directory entry: 122_1.bmp\n",
      "Skipping non-directory entry: 122_2.bmp\n",
      "Skipping non-directory entry: 122_3.bmp\n",
      "Skipping non-directory entry: 123_1.bmp\n",
      "Skipping non-directory entry: 123_2.bmp\n",
      "Skipping non-directory entry: 123_3.bmp\n",
      "Skipping non-directory entry: 124_1.bmp\n",
      "Skipping non-directory entry: 124_2.bmp\n",
      "Skipping non-directory entry: 124_3.bmp\n",
      "Skipping non-directory entry: 125_1.bmp\n",
      "Skipping non-directory entry: 125_2.bmp\n",
      "Skipping non-directory entry: 125_3.bmp\n",
      "Skipping non-directory entry: 126_1.bmp\n",
      "Skipping non-directory entry: 126_2.bmp\n",
      "Skipping non-directory entry: 126_3.bmp\n",
      "Skipping non-directory entry: 127_1.bmp\n",
      "Skipping non-directory entry: 127_2.bmp\n",
      "Skipping non-directory entry: 127_3.bmp\n",
      "Skipping non-directory entry: 128_1.bmp\n",
      "Skipping non-directory entry: 128_2.bmp\n",
      "Skipping non-directory entry: 128_3.bmp\n",
      "Skipping non-directory entry: 129_1.bmp\n",
      "Skipping non-directory entry: 129_2.bmp\n",
      "Skipping non-directory entry: 129_3.bmp\n",
      "Skipping non-directory entry: 130_1.bmp\n",
      "Skipping non-directory entry: 130_2.bmp\n",
      "Skipping non-directory entry: 130_3.bmp\n",
      "Skipping non-directory entry: 131_1.bmp\n",
      "Skipping non-directory entry: 131_2.bmp\n",
      "Skipping non-directory entry: 131_3.bmp\n",
      "Skipping non-directory entry: 131_4.bmp\n",
      "Skipping non-directory entry: 132_1.bmp\n",
      "Skipping non-directory entry: 132_2.bmp\n",
      "Skipping non-directory entry: 132_3.bmp\n",
      "Skipping non-directory entry: 133_1.bmp\n",
      "Skipping non-directory entry: 133_2.bmp\n",
      "Skipping non-directory entry: 133_3.bmp\n",
      "Skipping non-directory entry: 134_1.bmp\n",
      "Skipping non-directory entry: 134_2.bmp\n",
      "Skipping non-directory entry: 134_3.bmp\n",
      "Skipping non-directory entry: 135_1.bmp\n",
      "Skipping non-directory entry: 135_2.bmp\n",
      "Skipping non-directory entry: 135_3.bmp\n",
      "Skipping non-directory entry: 136_1.bmp\n",
      "Skipping non-directory entry: 136_2.bmp\n",
      "Skipping non-directory entry: 136_3.bmp\n",
      "Skipping non-directory entry: 137_1.bmp\n",
      "Skipping non-directory entry: 137_2.bmp\n",
      "Skipping non-directory entry: 137_3.bmp\n",
      "Skipping non-directory entry: 138_1.bmp\n",
      "Skipping non-directory entry: 138_2.bmp\n",
      "Skipping non-directory entry: 138_3.bmp\n",
      "Skipping non-directory entry: 139_1.bmp\n",
      "Skipping non-directory entry: 139_2.bmp\n",
      "Skipping non-directory entry: 139_3.bmp\n",
      "Skipping non-directory entry: 140_1.bmp\n",
      "Skipping non-directory entry: 140_2.bmp\n",
      "Skipping non-directory entry: 140_3.bmp\n",
      "Skipping non-directory entry: 141_1.bmp\n",
      "Skipping non-directory entry: 141_2.bmp\n",
      "Skipping non-directory entry: 141_3.bmp\n",
      "Skipping non-directory entry: 141_4.bmp\n",
      "Skipping non-directory entry: 142_1.bmp\n",
      "Skipping non-directory entry: 142_2.bmp\n",
      "Skipping non-directory entry: 142_3.bmp\n",
      "Skipping non-directory entry: 143_1.bmp\n",
      "Skipping non-directory entry: 143_2.bmp\n",
      "Skipping non-directory entry: 143_3.bmp\n",
      "Skipping non-directory entry: 144_1.bmp\n",
      "Skipping non-directory entry: 144_2.bmp\n",
      "Skipping non-directory entry: 144_3.bmp\n",
      "Skipping non-directory entry: 145_1.bmp\n",
      "Skipping non-directory entry: 145_2.bmp\n",
      "Skipping non-directory entry: 145_3.bmp\n",
      "Skipping non-directory entry: 146_1.bmp\n",
      "Skipping non-directory entry: 146_2.bmp\n",
      "Skipping non-directory entry: 146_3.bmp\n",
      "Skipping non-directory entry: 147_1.bmp\n",
      "Skipping non-directory entry: 147_2.bmp\n",
      "Skipping non-directory entry: 147_3.bmp\n",
      "Skipping non-directory entry: 148_1.bmp\n",
      "Skipping non-directory entry: 148_2.bmp\n",
      "Skipping non-directory entry: 148_3.bmp\n",
      "Skipping non-directory entry: 149_1.bmp\n",
      "Skipping non-directory entry: 149_2.bmp\n",
      "Skipping non-directory entry: 149_3.bmp\n",
      "Skipping non-directory entry: 150_1.bmp\n",
      "Skipping non-directory entry: 150_2.bmp\n",
      "Skipping non-directory entry: 150_3.bmp\n",
      "Skipping non-directory entry: 151_1.bmp\n",
      "Skipping non-directory entry: 151_2.bmp\n",
      "Skipping non-directory entry: 151_3.bmp\n",
      "Skipping non-directory entry: 152_1.bmp\n",
      "Skipping non-directory entry: 152_2.bmp\n",
      "Skipping non-directory entry: 152_3.bmp\n",
      "Skipping non-directory entry: 153_1.bmp\n",
      "Skipping non-directory entry: 153_2.bmp\n",
      "Skipping non-directory entry: 153_3.bmp\n",
      "Skipping non-directory entry: 154_1.bmp\n",
      "Skipping non-directory entry: 154_2.bmp\n",
      "Skipping non-directory entry: 154_3.bmp\n",
      "Skipping non-directory entry: 155_1.bmp\n",
      "Skipping non-directory entry: 155_2.bmp\n",
      "Skipping non-directory entry: 155_3.bmp\n",
      "Skipping non-directory entry: 156_1.bmp\n",
      "Skipping non-directory entry: 156_2.bmp\n",
      "Skipping non-directory entry: 156_3.bmp\n",
      "Skipping non-directory entry: 157_1.bmp\n",
      "Skipping non-directory entry: 157_2.bmp\n",
      "Skipping non-directory entry: 157_3.bmp\n",
      "Skipping non-directory entry: 158_1.bmp\n",
      "Skipping non-directory entry: 158_2.bmp\n",
      "Skipping non-directory entry: 158_3.bmp\n",
      "Skipping non-directory entry: 159_1.bmp\n",
      "Skipping non-directory entry: 159_2.bmp\n",
      "Skipping non-directory entry: 159_3.bmp\n",
      "Skipping non-directory entry: 160_1.bmp\n",
      "Skipping non-directory entry: 160_2.bmp\n",
      "Skipping non-directory entry: 160_3.bmp\n",
      "Skipping non-directory entry: 161_1.bmp\n",
      "Skipping non-directory entry: 161_2.bmp\n",
      "Skipping non-directory entry: 161_3.bmp\n",
      "Skipping non-directory entry: 162_1.bmp\n",
      "Skipping non-directory entry: 162_2.bmp\n",
      "Skipping non-directory entry: 162_3.bmp\n",
      "Skipping non-directory entry: 163_1.bmp\n",
      "Skipping non-directory entry: 163_2.bmp\n",
      "Skipping non-directory entry: 163_3.bmp\n",
      "Skipping non-directory entry: 164_1.bmp\n",
      "Skipping non-directory entry: 164_2.bmp\n",
      "Skipping non-directory entry: 164_3.bmp\n",
      "Skipping non-directory entry: 165_1.bmp\n",
      "Skipping non-directory entry: 165_2.bmp\n",
      "Skipping non-directory entry: 165_3.bmp\n",
      "Skipping non-directory entry: 166_1.bmp\n",
      "Skipping non-directory entry: 166_2.bmp\n",
      "Skipping non-directory entry: 166_3.bmp\n",
      "Skipping non-directory entry: 167_1.bmp\n",
      "Skipping non-directory entry: 167_2.bmp\n",
      "Skipping non-directory entry: 167_3.bmp\n",
      "Skipping non-directory entry: 168_1.bmp\n",
      "Skipping non-directory entry: 168_2.bmp\n",
      "Skipping non-directory entry: 168_3.bmp\n",
      "Skipping non-directory entry: 169_1.bmp\n",
      "Skipping non-directory entry: 169_2.bmp\n",
      "Skipping non-directory entry: 169_3.bmp\n",
      "Skipping non-directory entry: 170_1.bmp\n",
      "Skipping non-directory entry: 170_2.bmp\n",
      "Skipping non-directory entry: 170_3.bmp\n",
      "Skipping non-directory entry: 171_1.bmp\n",
      "Skipping non-directory entry: 171_2.bmp\n",
      "Skipping non-directory entry: 171_3.bmp\n",
      "Skipping non-directory entry: 172_1.bmp\n",
      "Skipping non-directory entry: 172_2.bmp\n",
      "Skipping non-directory entry: 172_3.bmp\n",
      "Skipping non-directory entry: 173_1.bmp\n",
      "Skipping non-directory entry: 173_2.bmp\n",
      "Skipping non-directory entry: 173_3.bmp\n",
      "Skipping non-directory entry: 174_1.bmp\n",
      "Skipping non-directory entry: 174_2.bmp\n",
      "Skipping non-directory entry: 174_3.bmp\n",
      "Skipping non-directory entry: 175_1.bmp\n",
      "Skipping non-directory entry: 175_2.bmp\n",
      "Skipping non-directory entry: 175_3.bmp\n",
      "Skipping non-directory entry: 176_1.bmp\n",
      "Skipping non-directory entry: 176_2.bmp\n",
      "Skipping non-directory entry: 176_3.bmp\n",
      "Skipping non-directory entry: 177_1.bmp\n",
      "Skipping non-directory entry: 177_2.bmp\n",
      "Skipping non-directory entry: 177_3.bmp\n",
      "Skipping non-directory entry: 178_1.bmp\n",
      "Skipping non-directory entry: 178_2.bmp\n",
      "Skipping non-directory entry: 178_3.bmp\n",
      "Skipping non-directory entry: 179_1.bmp\n",
      "Skipping non-directory entry: 179_2.bmp\n",
      "Skipping non-directory entry: 179_3.bmp\n",
      "Skipping non-directory entry: 180_1.bmp\n",
      "Skipping non-directory entry: 180_2.bmp\n",
      "Skipping non-directory entry: 180_3.bmp\n",
      "Skipping non-directory entry: 180_4.bmp\n",
      "Skipping non-directory entry: 181_1.bmp\n",
      "Skipping non-directory entry: 181_2.bmp\n",
      "Skipping non-directory entry: 181_3.bmp\n",
      "Skipping non-directory entry: 181_4.bmp\n",
      "Skipping non-directory entry: 182_1.bmp\n",
      "Skipping non-directory entry: 182_2.bmp\n",
      "Skipping non-directory entry: 182_3.bmp\n",
      "Skipping non-directory entry: 183_1.bmp\n",
      "Skipping non-directory entry: 183_2.bmp\n",
      "Skipping non-directory entry: 183_3.bmp\n",
      "Skipping non-directory entry: 184_1.bmp\n",
      "Skipping non-directory entry: 184_2.bmp\n",
      "Skipping non-directory entry: 184_3.bmp\n",
      "Skipping non-directory entry: 185_1.bmp\n",
      "Skipping non-directory entry: 185_2.bmp\n",
      "Skipping non-directory entry: 185_3.bmp\n",
      "Skipping non-directory entry: 186_1.bmp\n",
      "Skipping non-directory entry: 186_2.bmp\n",
      "Skipping non-directory entry: 186_3.bmp\n",
      "Skipping non-directory entry: 187_1.bmp\n",
      "Skipping non-directory entry: 187_2.bmp\n",
      "Skipping non-directory entry: 187_3.bmp\n",
      "Skipping non-directory entry: 188_1.bmp\n",
      "Skipping non-directory entry: 188_2.bmp\n",
      "Skipping non-directory entry: 188_3.bmp\n",
      "Skipping non-directory entry: 189_1.bmp\n",
      "Skipping non-directory entry: 189_2.bmp\n",
      "Skipping non-directory entry: 189_3.bmp\n",
      "Skipping non-directory entry: 189_4.bmp\n",
      "Skipping non-directory entry: 190_1.bmp\n",
      "Skipping non-directory entry: 190_2.bmp\n",
      "Skipping non-directory entry: 190_3.bmp\n",
      "Skipping non-directory entry: 191_1.bmp\n",
      "Skipping non-directory entry: 191_2.bmp\n",
      "Skipping non-directory entry: 191_3.bmp\n",
      "Skipping non-directory entry: 191_4.bmp\n",
      "Skipping non-directory entry: 192_1.bmp\n",
      "Skipping non-directory entry: 192_2.bmp\n",
      "Skipping non-directory entry: 192_3.bmp\n",
      "Skipping non-directory entry: 193_1.bmp\n",
      "Skipping non-directory entry: 193_2.bmp\n",
      "Skipping non-directory entry: 193_3.bmp\n",
      "Skipping non-directory entry: 194_1.bmp\n",
      "Skipping non-directory entry: 194_2.bmp\n",
      "Skipping non-directory entry: 194_3.bmp\n",
      "Skipping non-directory entry: 195_1.bmp\n",
      "Skipping non-directory entry: 195_2.bmp\n",
      "Skipping non-directory entry: 195_3.bmp\n",
      "Skipping non-directory entry: 196_1.bmp\n",
      "Skipping non-directory entry: 196_2.bmp\n",
      "Skipping non-directory entry: 196_3.bmp\n",
      "Skipping non-directory entry: 196_4.bmp\n",
      "Skipping non-directory entry: 197_1.bmp\n",
      "Skipping non-directory entry: 197_2.bmp\n",
      "Skipping non-directory entry: 197_3.bmp\n",
      "Skipping non-directory entry: 198_1.bmp\n",
      "Skipping non-directory entry: 198_2.bmp\n",
      "Skipping non-directory entry: 198_3.bmp\n",
      "Skipping non-directory entry: 199_1.bmp\n",
      "Skipping non-directory entry: 199_2.bmp\n",
      "Skipping non-directory entry: 199_3.bmp\n",
      "Skipping non-directory entry: 200_1.bmp\n",
      "Skipping non-directory entry: 200_2.bmp\n",
      "Skipping non-directory entry: 200_3.bmp\n",
      "Skipping non-directory entry: 201_1.bmp\n",
      "Skipping non-directory entry: 201_2.bmp\n",
      "Skipping non-directory entry: 201_3.bmp\n",
      "Skipping non-directory entry: 202_1.bmp\n",
      "Skipping non-directory entry: 202_2.bmp\n",
      "Skipping non-directory entry: 202_3.bmp\n",
      "Skipping non-directory entry: 203_1.bmp\n",
      "Skipping non-directory entry: 203_2.bmp\n",
      "Skipping non-directory entry: 203_3.bmp\n",
      "Skipping non-directory entry: 203_4.bmp\n",
      "Skipping non-directory entry: 204_1.bmp\n",
      "Skipping non-directory entry: 204_2.bmp\n",
      "Skipping non-directory entry: 204_3.bmp\n",
      "Skipping non-directory entry: 205_1.bmp\n",
      "Skipping non-directory entry: 205_2.bmp\n",
      "Skipping non-directory entry: 205_3.bmp\n",
      "Skipping non-directory entry: 206_1.bmp\n",
      "Skipping non-directory entry: 206_2.bmp\n",
      "Skipping non-directory entry: 206_3.bmp\n",
      "Skipping non-directory entry: 207_1.bmp\n",
      "Skipping non-directory entry: 207_2.bmp\n",
      "Skipping non-directory entry: 207_3.bmp\n",
      "Skipping non-directory entry: 208_1.bmp\n",
      "Skipping non-directory entry: 208_2.bmp\n",
      "Skipping non-directory entry: 208_3.bmp\n",
      "Skipping non-directory entry: 209_1.bmp\n",
      "Skipping non-directory entry: 209_2.bmp\n",
      "Skipping non-directory entry: 209_3.bmp\n",
      "Skipping non-directory entry: 210_1.bmp\n",
      "Skipping non-directory entry: 210_2.bmp\n",
      "Skipping non-directory entry: 210_3.bmp\n",
      "Skipping non-directory entry: 211_1.bmp\n",
      "Skipping non-directory entry: 211_2.bmp\n",
      "Skipping non-directory entry: 211_3.bmp\n",
      "Skipping non-directory entry: 212_1.bmp\n",
      "Skipping non-directory entry: 212_2.bmp\n",
      "Skipping non-directory entry: 212_3.bmp\n",
      "Skipping non-directory entry: 212_4.bmp\n",
      "Skipping non-directory entry: 212_5.bmp\n",
      "Skipping non-directory entry: 213_1.bmp\n",
      "Skipping non-directory entry: 213_2.bmp\n",
      "Skipping non-directory entry: 213_3.bmp\n",
      "Skipping non-directory entry: 213_4.bmp\n",
      "Skipping non-directory entry: 213_5.bmp\n",
      "Skipping non-directory entry: 213_6.bmp\n",
      "Skipping non-directory entry: 214_1.bmp\n",
      "Skipping non-directory entry: 214_2.bmp\n",
      "Skipping non-directory entry: 214_3.bmp\n",
      "Skipping non-directory entry: 214_4.bmp\n",
      "Skipping non-directory entry: 214_5.bmp\n",
      "Skipping non-directory entry: 214_6.bmp\n",
      "Skipping non-directory entry: 215_1.bmp\n",
      "Skipping non-directory entry: 215_2.bmp\n",
      "Skipping non-directory entry: 215_3.bmp\n",
      "Skipping non-directory entry: 215_4.bmp\n",
      "Skipping non-directory entry: 216_1.bmp\n",
      "Skipping non-directory entry: 216_2.bmp\n",
      "Skipping non-directory entry: 216_3.bmp\n",
      "Skipping non-directory entry: 216_4.bmp\n",
      "Skipping non-directory entry: 217_1.bmp\n",
      "Skipping non-directory entry: 217_2.bmp\n",
      "Skipping non-directory entry: 217_3.bmp\n",
      "Skipping non-directory entry: 218_1.bmp\n",
      "Skipping non-directory entry: 218_2.bmp\n",
      "Skipping non-directory entry: 218_3.bmp\n",
      "Skipping non-directory entry: 218_4.bmp\n",
      "Skipping non-directory entry: 218_5.bmp\n",
      "Skipping non-directory entry: 218_6.bmp\n",
      "Skipping non-directory entry: 219_1.bmp\n",
      "Skipping non-directory entry: 219_2.bmp\n",
      "Skipping non-directory entry: 219_3.bmp\n",
      "Skipping non-directory entry: 219_4.bmp\n",
      "Skipping non-directory entry: 219_5.bmp\n",
      "Skipping non-directory entry: 220_1.bmp\n",
      "Skipping non-directory entry: 220_2.bmp\n",
      "Skipping non-directory entry: 220_3.bmp\n",
      "Skipping non-directory entry: 221_1.bmp\n",
      "Skipping non-directory entry: 221_2.bmp\n",
      "Skipping non-directory entry: 221_3.bmp\n",
      "Skipping non-directory entry: Thumbs.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANAY\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input to `.fit()` should have rank 4. Got array with shape: (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 63\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Data augmentation (optional)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# ... (consider including relevant data augmentation techniques for grayscale images)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# Example: rotation_range=10, width_shift_range=0.1, height_shift_range=0.1\u001b[39;00m\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m datagen\u001b[38;5;241m.\u001b[39mfit(X)  \u001b[38;5;66;03m# Fit data augmentation on training data\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Load pre-trained VGG16 model\u001b[39;00m\n\u001b[0;32m     66\u001b[0m base_model \u001b[38;5;241m=\u001b[39m VGG16(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Grayscale channel\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1490\u001b[0m, in \u001b[0;36mImageDataGenerator.fit\u001b[1;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[0;32m   1488\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m-> 1490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput to `.fit()` should have rank 4. Got array with shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1492\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1493\u001b[0m     )\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m}:\n\u001b[0;32m   1495\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected input to be images (as Numpy array) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1497\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfollowing the data format convention \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1507\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m channels).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1508\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Input to `.fit()` should have rank 4. Got array with shape: (0,)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For data augmentation (optional)\n",
    "from sklearn.preprocessing import OneHotEncoder  # For label encoding\n",
    "import cv2  # For image processing\n",
    "\n",
    "# Path to your preprocessed images folder (ensure it's a valid directory)\n",
    "data_dir = \"C:/Users/PRANAY/OneDrive/Desktop/Ear Recoginition System_Mini Project_6sem/ear/processed/221\"\n",
    "\n",
    "# Define number of classes (number of subjects in your dataset) based on the description\n",
    "num_classes = 221  # Assuming each folder represents a subject\n",
    "\n",
    "# Load and preprocess data (assuming labels are encoded in folder names)\n",
    "X = []\n",
    "y = []\n",
    "for folder_name in os.listdir(data_dir):\n",
    "  label = folder_name  # Assuming folder name represents the label (subject ID)\n",
    "  y.append(label)\n",
    "\n",
    "  # Handle non-directory entries (e.g., files within data_dir)\n",
    "  if not os.path.isdir(os.path.join(data_dir, folder_name)):\n",
    "    print(f\"Skipping non-directory entry: {folder_name}\")\n",
    "    continue\n",
    "\n",
    "  # Get all filenames within the current folder\n",
    "  filenames = [f for f in os.listdir(os.path.join(data_dir, folder_name)) if os.path.isfile(os.path.join(data_dir, folder_name, f))]  # Filter for files only\n",
    "\n",
    "  for filename in filenames:\n",
    "    img_path = os.path.join(data_dir, folder_name, filename)\n",
    "\n",
    "    # Handle invalid images (optional)\n",
    "    try:\n",
    "      img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "      if img is None:\n",
    "        print(f\"Skipping invalid image: {img_path}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "      print(f\"Error reading image: {img_path} - {e}\")\n",
    "      continue\n",
    "\n",
    "    # No resizing needed as images are already 50x180 according to description\n",
    "    # Normalize (optional)\n",
    "    img = img.astype('float32') / 255.0  # Normalize pixel values between 0 and 1\n",
    "    X.append(img)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# Reshape y to a 2D array (if necessary)\n",
    "y = np.array([[l] for l in y])  # Reshape y if it's not already 2D\n",
    "\n",
    "# One-hot encode labels (modify if labels are not folder names)\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Data augmentation (optional)\n",
    "datagen = ImageDataGenerator(\n",
    "    # ... (consider including relevant data augmentation techniques for grayscale images)\n",
    "    # Example: rotation_range=10, width_shift_range=0.1, height_shift_range=0.1\n",
    ")\n",
    "datagen.fit(X)  # Fit data augmentation on training data\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(50, 180, 1))  # Grayscale channel\n",
    "\n",
    "# Freeze pre-trained layers (optional, you can experiment with unfreezing some)\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(datagen.flow(X, y, batch_size=32), epochs=10)  # Use data augmentation (optional)\n",
    "\n",
    "# Save the model (optional)\n",
    "model.save('ear_recognition_model.h5')\n",
    "\n",
    "# ... (use the trained model for prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5026d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d056aaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c7c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440affb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef3155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c1012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51bbec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84557fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54fd64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd92992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb4628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66cf8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For data augmentation (optional)\n",
    "from sklearn.preprocessing import OneHotEncoder  # For label encoding\n",
    "\n",
    "# Path to your raw images folder (modify if needed)\n",
    "data_dir = \"C:/Users/PRANAY/OneDrive/Desktop/Ear Recoginition System_Mini Project_6sem/ear/raw\"\n",
    "\n",
    "# Define number of classes (number of subjects in your dataset)\n",
    "num_classes = 125\n",
    "\n",
    "# Load and preprocess raw images\n",
    "X = []\n",
    "y = []  # List to store labels (modify as needed)\n",
    "for filename in os.listdir(data_dir):\n",
    "    if not filename.endswith('.bmp'):\n",
    "        continue  # Skip non-BMP files\n",
    "    img_path = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Extract label from filename or separate label directory (modify as needed)\n",
    "    # This example assumes the label is the first part of the filename before the underscore\n",
    "    label = filename.split(\"_\")[0]\n",
    "    y.append(label)\n",
    "\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('RGB')  # Convert to RGB if grayscale\n",
    "        img = img.resize((224, 224))\n",
    "        img_array = np.array(img)\n",
    "        # Normalize (optional)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        if img_array is not None:\n",
    "            X.append(img_array)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {img_path}: {e}\")\n",
    "\n",
    "if len(X) == 0:\n",
    "    print(\"No valid images found in the dataset. Please check the dataset.\")\n",
    "else:\n",
    "    X = np.array(X, dtype=np.float32)  # Ensure data type\n",
    "\n",
    "    # One-hot encode labels\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y = encoder.fit_transform(np.array([[l] for l in y]))  # Reshape for encoder\n",
    "\n",
    "    # Data augmentation (optional)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,  # Randomly rotate images\n",
    "        width_shift_range=0.2,  # Randomly shift images horizontally\n",
    "        height_shift_range=0.2,  # Randomly shift images vertically\n",
    "        shear_range=0.2,  # Randomly shear images\n",
    "        zoom_range=0.2,  # Randomly zoom images\n",
    "        horizontal_flip=True  # Randomly flip images horizontally\n",
    "    )\n",
    "    datagen.fit(X)  # Fit data augmentation on training data\n",
    "\n",
    "    # Load pre-trained VGG16 model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze pre-trained layers (optional, you can experiment with unfreezing some)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(datagen.flow(X, y, batch_size=32), epochs=16)  # Use data augmentation\n",
    "\n",
    "    # Evaluate the model and print final test accuracy\n",
    "    test_loss, test_acc = model.evaluate(X, y)  # Assuming X and y are for validation/testing\n",
    "    print('Test accuracy:', test_acc)\n",
    "\n",
    "    # Save the model (optional)\n",
    "    # model.save('ear_recognition_model.h5')\n",
    "\n",
    "    # ... (use the trained model for prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43177eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15889cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f01cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6722cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200444a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d136856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cba144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96efd775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANAY\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PRANAY\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_encoded: (394, 246)\n",
      "Shape of y_val_encoded: (99, 246)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANAY\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.0118 - loss: 5.3783 - val_accuracy: 0.0000e+00 - val_loss: 4.9661\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.0076 - loss: 4.8959 - val_accuracy: 0.0000e+00 - val_loss: 4.9843\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.0148 - loss: 4.9862 - val_accuracy: 0.0000e+00 - val_loss: 4.9293\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.0176 - loss: 4.8720 - val_accuracy: 0.0000e+00 - val_loss: 4.9023\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.0187 - loss: 4.9153 - val_accuracy: 0.0000e+00 - val_loss: 4.8791\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.0087 - loss: 4.8782 - val_accuracy: 0.0000e+00 - val_loss: 4.8609\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.0074 - loss: 4.9123 - val_accuracy: 0.0000e+00 - val_loss: 4.8291\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.0105 - loss: 4.8431 - val_accuracy: 0.0000e+00 - val_loss: 4.8641\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.0172 - loss: 4.8437 - val_accuracy: 0.0000e+00 - val_loss: 4.8693\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.0086 - loss: 4.8957 - val_accuracy: 0.0000e+00 - val_loss: 4.8520\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.0065 - loss: 4.8755 - val_accuracy: 0.0000e+00 - val_loss: 4.8801\n",
      "Epoch 12/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.0128 - loss: 4.8442 - val_accuracy: 0.0000e+00 - val_loss: 4.8533\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 4.8552\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50  # Explore different pre-trained models\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For data augmentation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard  # For early stopping and visualization\n",
    "from sklearn.preprocessing import OneHotEncoder  # For label encoding\n",
    "from sklearn.model_selection import train_test_split  # For splitting data\n",
    "\n",
    "# Data path (modify as needed)\n",
    "data_dir = \"C:/Users/PRANAY/OneDrive/Desktop/Ear Recoginition System_Mini Project_6sem/ear/raw\"\n",
    "\n",
    "# Define number of classes (number of subjects in your dataset)\n",
    "num_classes = 123\n",
    "\n",
    "# Function to load and preprocess images with label extraction\n",
    "def load_and_preprocess_images(data_dir):\n",
    "    images, labels = [], []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if not filename.endswith('.bmp'):\n",
    "            continue\n",
    "        img_path = os.path.join(data_dir, filename)\n",
    "\n",
    "        # Extract label from filename (modify if labels are stored differently)\n",
    "        label = filename.split(\"_\")[0]\n",
    "        labels.append(label)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img = img.convert('RGB')  # Convert to grayscale if needed\n",
    "            img = img.resize((224, 224))  # Adjust input size if using different models\n",
    "            img_array = np.array(img)\n",
    "            img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "            images.append(img_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load all images and labels\n",
    "X, y = load_and_preprocess_images(data_dir)\n",
    "\n",
    "# Split data into training and validation sets (adjust test_size as needed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot encode labels\n",
    "# One-hot encode labels (handle unknown categories with 'ignore')\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "y_train = encoder.fit_transform(np.array([[l] for l in y_train]))\n",
    "y_val = encoder.transform(np.array([[l] for l in y_val]))\n",
    "\n",
    "# ... your existing code up to label encoding\n",
    "\n",
    "# Reshape labels for encoding (remove extra [])\n",
    "y_train_encoded = encoder.fit_transform(np.array([l for l in y_train]))\n",
    "y_val_encoded = encoder.transform(np.array([l for l in y_val]))\n",
    "\n",
    "print(\"Shape of y_train_encoded:\", y_train_encoded.shape)\n",
    "print(\"Shape of y_val_encoded:\", y_val_encoded.shape)\n",
    "\n",
    "# ... rest of your code\n",
    "\n",
    "# ... rest of the code remains the same (data augmentation, model definition, training, etc.)\n",
    "\n",
    "# Data augmentation configuration\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Experiment with different pre-trained models\n",
    "# Choose one to uncomment:\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # May perform better\n",
    "\n",
    "# Freeze pre-trained layers (optional)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers (consider adding Dropout for regularization)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.25)(x)  # Regularization to prevent overfitting\n",
    "# Add final layers for classification\n",
    "predictions = Dense(num_classes, activation='softmax')(x)  # Multi-class classification\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model (experiment with optimizer and learning rate)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks (early stopping and tensorboard for monitoring)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)  # Stop training if validation loss doesn't improve for 5 epochs\n",
    "tensorboard = TensorBoard(log_dir='./logs')  # Visualize training process in TensorBoard\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    epochs=20,  # Adjust number of epochs\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping, tensorboard])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Optionally save the trained model\n",
    "# model.save('ear_recognition_model.h5')\n",
    "\n",
    "# Use the trained model for prediction on new ear images (code not included here)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fdeced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons in final layer: 125\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of neurons in final layer:\", predictions.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f33f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f8a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e5a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4efb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbfc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599492ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76ff46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439919c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38ab1f0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m load_and_preprocess_images(data_dir)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Split data into training, validation, and test sets (adjust test_size as needed)\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m X_train, X_val, X_test, y_train, y_val, y_test \u001b[38;5;241m=\u001b[39m train_test_split(images, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# One-hot encode labels (handle unknown categories with 'ignore')\u001b[39;00m\n\u001b[0;32m     48\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import VGG16, ResNet50  # Explore different models\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard  # For early stopping and visualization\n",
    "from sklearn.preprocessing import OneHotEncoder  # For label encoding\n",
    "from sklearn.model_selection import train_test_split  # For splitting data\n",
    "\n",
    "# Data path (modify as needed)\n",
    "data_dir = \"C:/Users/PRANAY/OneDrive/Desktop/Ear Recoginition System_Mini Project_6sem/ear/raw\"\n",
    "\n",
    "# Define number of classes (number of subjects in your dataset)\n",
    "num_classes = 125\n",
    "\n",
    "# Function to load and preprocess images with label extraction\n",
    "def load_and_preprocess_images(data_dir):\n",
    "  images, labels = [], []\n",
    "  for filename in os.listdir(data_dir):\n",
    "    if not filename.endswith('.bmp'):\n",
    "      continue\n",
    "    img_path = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Extract label from filename (modify if labels are stored differently)\n",
    "    label = filename.split(\"_\")[0]\n",
    "    labels.append(label)\n",
    "\n",
    "    try:\n",
    "      img = Image.open(img_path)\n",
    "      img = img.convert('RGB')  # Convert to grayscale if needed\n",
    "      img = img.resize((224, 224))  # Adjust input size if using different models\n",
    "      img_array = np.array(img)\n",
    "      img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "      images.append(img_array)\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing image {img_path}: {e}\")\n",
    "  return images, labels\n",
    "\n",
    "# Load all images and labels\n",
    "images, labels = load_and_preprocess_images(data_dir)\n",
    "\n",
    "# Split data into training and validation sets (adjust test_size if needed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot encode labels (handle unknown categories with 'ignore')\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "y_train_encoded = encoder.fit_transform(np.array([[l] for l in y_train]))\n",
    "y_val_encoded = encoder.transform(np.array([[l] for l in y_val]))\n",
    "\n",
    "# Data augmentation configuration\n",
    "datagen = ImageDataGenerator(\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  # Consider adding noise augmentation here\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Experiment with different pre-trained models (ResNet50 uncommented here)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # Optional: Use VGG16\n",
    "\n",
    "# Freeze pre-trained layers (optional)\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Add custom layers with Dropout for regularization\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # Add Dropout for regularization\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model (experiment with learning rate and optimizer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], learning_rate=0.001)  # Adjust learning rate\n",
    "\n",
    "# Define callbacks (early stopping and tensorboard for monitoring)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# tensorboard = TensorBoard(log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0a740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4df0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53d590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9f712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944efb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6232a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0471c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086dea21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb3b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f48ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad03ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANAY\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANAY\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 7s/step - accuracy: 0.0260 - loss: 5.3510\n",
      "Epoch 2/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 7s/step - accuracy: 0.0418 - loss: 4.6818\n",
      "Epoch 3/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 7s/step - accuracy: 0.0809 - loss: 4.2569\n",
      "Epoch 4/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7s/step - accuracy: 0.1262 - loss: 3.7730\n",
      "Epoch 5/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 7s/step - accuracy: 0.2371 - loss: 3.1842\n",
      "Epoch 6/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 7s/step - accuracy: 0.3254 - loss: 2.7224\n",
      "Epoch 7/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 7s/step - accuracy: 0.4777 - loss: 1.9972\n",
      "Epoch 8/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7s/step - accuracy: 0.5554 - loss: 1.6541\n",
      "Epoch 9/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 6s/step - accuracy: 0.6171 - loss: 1.3944\n",
      "Epoch 10/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 6s/step - accuracy: 0.6953 - loss: 1.0793\n",
      "Epoch 11/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 6s/step - accuracy: 0.8225 - loss: 0.7416\n",
      "Epoch 12/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.8634 - loss: 0.5034\n",
      "Epoch 13/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 7s/step - accuracy: 0.9153 - loss: 0.3904\n",
      "Epoch 14/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 7s/step - accuracy: 0.8864 - loss: 0.4182\n",
      "Epoch 15/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 7s/step - accuracy: 0.9020 - loss: 0.3985\n",
      "Epoch 16/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7s/step - accuracy: 0.9157 - loss: 0.3640\n",
      "Epoch 17/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7s/step - accuracy: 0.9129 - loss: 0.3837\n",
      "Epoch 18/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 6s/step - accuracy: 0.9473 - loss: 0.2108\n",
      "Epoch 19/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 6s/step - accuracy: 0.9510 - loss: 0.1952\n",
      "Epoch 20/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 6s/step - accuracy: 0.9461 - loss: 0.1797\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.0014 - loss: 187.9438  \n",
      "Test accuracy: 0.008113590069115162\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import ResNet50  # Consider using ResNet50 instead of VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Path to your raw images folder (modify if needed)\n",
    "data_dir = \"C:/Users/PRANAY/OneDrive/Desktop/Ear Recoginition System_Mini Project_6sem/ear/raw\"\n",
    "\n",
    "# Define number of classes (number of subjects in your dataset)\n",
    "num_classes = 125\n",
    "\n",
    "# Load and preprocess raw images\n",
    "X = []\n",
    "y = []  # List to store labels (modify as needed)\n",
    "for filename in os.listdir(data_dir):\n",
    "    if not filename.endswith('.bmp'):\n",
    "        continue  # Skip non-BMP files\n",
    "    img_path = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Extract label from filename or separate label directory (modify as needed)\n",
    "    # This example assumes the label is the first part of the filename before the underscore\n",
    "    label = filename.split(\"_\")[0]\n",
    "    y.append(label)\n",
    "\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('RGB')  # Convert to RGB if grayscale\n",
    "        img = img.resize((224, 224))\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Normalize (optional)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "\n",
    "        if img_array is not None:\n",
    "            X.append(img_array)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {img_path}: {e}\")\n",
    "\n",
    "if len(X) == 0:\n",
    "    print(\"No valid images found in the dataset. Please check the dataset.\")\n",
    "else:\n",
    "    X = np.array(X, dtype=np.float32)  # Ensure data type\n",
    "\n",
    "    # One-hot encode labels\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y = encoder.fit_transform(np.array([[l] for l in y]))  # Reshape for encoder\n",
    "\n",
    "    # Data augmentation (optional)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        # Add noise or blurring for further augmentation\n",
    "        # noise_factor=0.1  # Example of adding noise\n",
    "        # blur_radius=(0.5, 1.0)  # Example of blurring\n",
    "    )\n",
    "    datagen.fit(X)  # Fit data augmentation on training data\n",
    "\n",
    "    # Load pre-trained ResNet50 model\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze some of the pre-trained layers (experiment with how many)\n",
    "    for layer in base_model.layers[:10]:  # Freeze the first 10 layers\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers with dropout for regularization\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.2)(x)  # Add dropout with 20% probability of dropping units\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compile the model with Adam optimizer and categorical crossentropy loss\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with data augmentation\n",
    "    history = model.fit(datagen.flow(X, y, batch_size=32), epochs=10)  # Experiment with epochs\n",
    "\n",
    "    # Evaluate the model and print final test accuracy\n",
    "    test_loss, test_acc = model.evaluate(X, y)  # Assuming X and y are for validation/testing\n",
    "    print('Test accuracy:', test_acc)\n",
    "\n",
    "    # Save the model (optional)\n",
    "    model.save('ear_recognition_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ba265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0602a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
